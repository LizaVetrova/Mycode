# -*- coding: utf-8 -*-
"""ML_3.6

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BGXlnnF0TTWoEQ1cUZYUY2oA0Hys3CCg
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, r2_score, mean_squared_error
from sklearn.model_selection import train_test_split

from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import ComplementNB
from sklearn.naive_bayes import GaussianNB

data = load_breast_cancer()

X = data.data
y = data.target

x_train, x_test, y_train, y_test = train_test_split(X,y, random_state = 7,
                                                    test_size = 0.2)

"""# 1. На использованном в работе наборе данных примените другие вариации модели наивного Байеса - Мультономиальный, Бернулли, категориальные и комплементарный. Для каждой модели сделайте вывод о ее применимости.

## MultinomialNB
"""

clf = MultinomialNB()

clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print('Confusion matrix \n', confusion_matrix(y_test, y_pred))
print('Accuracy= ', round(accuracy_score(y_test, y_pred), 3))
print('F1_score= ', round(f1_score(y_test, y_pred), 3))

"""## BernoulliNB"""

bernoulli_nb = BernoulliNB()

bernoulli_nb.fit(x_train, y_train)

y_pred1 = bernoulli_nb.predict(x_test)

print('Confusion matrix \n', confusion_matrix(y_test, y_pred1))
print('Accuracy= ', round(accuracy_score(y_test, y_pred1), 3))
print('F1_score= ', round(f1_score(y_test, y_pred1), 3))

"""## CategoricalNB"""

categorical_nb = CategoricalNB(min_categories= 50).fit(x_train, y_train)

y_pred2 = categorical_nb.predict(x_test)

print('Confusion matrix \n', confusion_matrix(y_test, y_pred2))
print('Accuracy= ', round(accuracy_score(y_test, y_pred2), 3))
print('F1_score= ', round(f1_score(y_test, y_pred2), 3))

"""## ComplementNB"""

complement_nb = ComplementNB()

complement_nb.fit(x_train, y_train)

y_pred3 = complement_nb.predict(x_test)

print('Confusion matrix \n', confusion_matrix(y_test, y_pred3))
print('Accuracy= ', round(accuracy_score(y_test, y_pred3), 3))
print('F1_score= ', round(f1_score(y_test, y_pred3), 3))

"""# 2. Загрузите набор данных о выживших на титанике, прилагающийся к этой работе. Повторите на нем моделирование из методических указаний. Попробуйте разные варианты байесовского классификатора в зависимости от форм расрпеделния эмпирических данных."""

df = pd.read_csv('titanic.csv')
df.head()

X = df.drop(['Survived', 'PassengerId', 'Fare'], axis = 1)
y = df['Survived']

X.head()

x_train1, x_test1, y_train1, y_test1 = train_test_split(X,y, random_state = 7,
                                                    test_size = 0.2)

gaussian_nb = GaussianNB()

gaussian_nb.fit(x_train1, y_train1)

y_pred4 = gaussian_nb.predict(x_test1)

print('Confusion matrix\n', confusion_matrix(y_test1, y_pred4))
print('Accuracy= ', round(accuracy_score(y_test, y_pred4), 3))
print('F1_score= ', round(f1_score(y_test, y_pred4), 3))

f = plt.figure(figsize=(15, 7))
for i in range(8):
    plt.subplot(2, 5, i+1)
    plt.hist(X[X.columns[i]])
    plt.xlabel(X.columns[i])
f.subplots_adjust(hspace = 0.9, wspace = 0.3)
plt.suptitle('Гистограммы признаков',fontsize=14)
plt.show()

X_new = np.array(X['Age']).reshape(-1,1)

x_train2, x_test2, y_train2, y_test2 = train_test_split(X_new,y, random_state = 7,
                                                    test_size = 0.2)

"""## GaussianNB"""

gaussian_nb = GaussianNB()

gaussian_nb.fit(x_train2, y_train2)

y_pred5 = gaussian_nb.predict(x_test2)

print('Confusion matrix\n', confusion_matrix(y_test2, y_pred5))
print('Accuracy= ',  round(accuracy_score(y_test2, y_pred5), 3))
print('F1_score= ', round(f1_score(y_test2, y_pred5), 3))

"""## MultinomialNB"""

clf = MultinomialNB()

clf.fit(x_train1, y_train1)

y_pred6 = clf.predict(x_test1)

print('Confusion matrix\n', confusion_matrix(y_test1, y_pred6))
print('Accuracy= ',  round(accuracy_score(y_test1, y_pred6), 3))
print('F1_score= ', round(f1_score(y_test1, y_pred6), 3))

"""## BernoulliNB"""

bernoulli_nb = BernoulliNB()
bernoulli_nb.fit(x_train1, y_train1)
y_pred7 = bernoulli_nb.predict(x_test1)

print('Confusion matrix\n', confusion_matrix(y_test1, y_pred7))
print('Accuracy= ',  round(accuracy_score(y_test1, y_pred7), 3))
print('F1_score= ', round(f1_score(y_test1, y_pred7), 3))

"""## Categorical"""

categorical_nb = CategoricalNB(min_categories= 1000).fit(x_train1, y_train1)

y_pred8 = categorical_nb.predict(x_test1)

print('Confusion matrix\n', confusion_matrix(y_test1, y_pred8))
print('Accuracy= ',  round(accuracy_score(y_test1, y_pred8), 3))
print('F1_score= ', round(f1_score(y_test1, y_pred8), 3))

"""## Complement"""

complement_nb = ComplementNB()

complement_nb.fit(x_train1, y_train1)

y_pred9 = complement_nb.predict(x_test1)

print('Confusion matrix\n', confusion_matrix(y_test1, y_pred9))
print('Accuracy= ',  round(accuracy_score(y_test1, y_pred9), 3))
print('F1_score= ', round(f1_score(y_test1, y_pred9), 3))

"""# 3. Загрузите набор данных о Титанике с сайта Kaggle. Обратите внимание на обилие категориальных переменных. Примените на нем наивный байесовский классификатор.

"""

titanic = pd.read_csv('/content/Titanic-Dataset.csv')
tit = titanic.dropna()

X_titanic = tit.drop(['Survived', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis = 1)
y_titanic = tit['Survived']

f = plt.figure(figsize=(15, 7))
for i in range(5):
    plt.subplot(2, 5, i+1)
    plt.hist(X_titanic[X_titanic.columns[i]])
    plt.xlabel(X_titanic.columns[i])
f.subplots_adjust(hspace = 0.9, wspace = 0.3)
plt.suptitle('Гистограммы признаков',fontsize=14)
plt.show()

x_train3, x_test3, y_train3, y_test3 = train_test_split(X_titanic,y_titanic, random_state = 7,
                                                    test_size = 0.2)

"""## BernoulliNB"""

bernoulli_nb = BernoulliNB()

bernoulli_nb.fit(x_train3, y_train3)

y_pred10 = bernoulli_nb.predict(x_test3)

print('Confusion matrix\n', confusion_matrix(y_test3, y_pred10))
print('Accuracy= ', round(accuracy_score(y_test3, y_pred10), 3))
print('F1_score= ', round(f1_score(y_test3, y_pred10), 3))

"""## CategoricalNB"""

categorical_nb = CategoricalNB(min_categories= 50).fit(x_train3, y_train3)

y_pred11 = categorical_nb.predict(x_test3)

print('Confusion matrix\n', confusion_matrix(y_test3, y_pred11))
print('Accuracy= ', round(accuracy_score(y_test3, y_pred11), 3))
print('F1_score= ', round(f1_score(y_test3, y_pred11), 3))

"""## MultinomialNB"""

clf = MultinomialNB()

clf.fit(x_train3, y_train3)

y_pred12 = clf.predict(x_test3)

print('Confusion matrix\n', confusion_matrix(y_test3, y_pred12))
print('Accuracy= ', round(accuracy_score(y_test3, y_pred12), 3))
print('F1_score= ', round(f1_score(y_test3, y_pred12), 3))

"""## ComplementNB"""

complement_nb = ComplementNB()

complement_nb.fit(x_train3, y_train3)

y_pred13 = complement_nb.predict(x_test3)

print('Confusion matrix\n', confusion_matrix(y_test3, y_pred13))
print('Accuracy= ', round(accuracy_score(y_test3, y_pred13), 3))
print('F1_score= ', round(f1_score(y_test3, y_pred13), 3))

"""## GaussianNB"""

gaussian_nb = GaussianNB()

gaussian_nb.fit(x_train3, y_train3)

y_pred14 = gaussian_nb.predict(x_test3)

print('Confusion matrix\n', confusion_matrix(y_test3, y_pred14))
print('Accuracy= ', round(accuracy_score(y_test3, y_pred14), 3))
print('F1_score= ', round(f1_score(y_test3, y_pred14), 3))